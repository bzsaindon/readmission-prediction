ggplot(DATAIN, aes(factor(CLUSTERCATEGORY), MEMBERCOUNT, fill = MEMBERRATING)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle("Distribution of Users by Group and Rating") +
annotate("text", label = "R2 = 0.999", x = 4, y = 50, fontface = 3)
ggplot(DATAIN, aes(factor(CLUSTERCATEGORY), MEMBERCOUNT, fill = MEMBERRATING)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle("Distribution of Users by Group and Rating") +
annotate("text", label = "R2 = 0.999", x = 4, y = 500, fontface = 3)
ggplot(DATAIN, aes(factor(CLUSTERCATEGORY), MEMBERCOUNT, fill = MEMBERRATING)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle("Distribution of Users by Group and Rating") +
annotate("text", label = "R2 = 0.999", x = 4, y = 200, fontface = 3)
ggplot(DATAIN, aes(factor(CLUSTERCATEGORY), MEMBERCOUNT, fill = MEMBERRATING)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle("Distribution of Users by Group and Rating") +
annotate("text", label = "R2 = 0.999", x = 4, y = 100, fontface = 3)
ggplot(DATAIN, aes(factor(CLUSTERCATEGORY), MEMBERCOUNT, fill = MEMBERRATING)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle("Distribution of Users by Group and Rating") +
annotate("text", label = "P = 0.999", x = 4, y = 100, fontface = 3)
ptext=c("P = 0.999")
ggplot(DATAIN, aes(factor(CLUSTERCATEGORY), MEMBERCOUNT, fill = MEMBERRATING)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle("Distribution of Users by Group and Rating") +
annotate("text", label = ptext, x = 4, y = 100, fontface = 3)
pvalue = 0.999
ptext=paste("P = ", pvalue)
ptext
pvalue = 0.05
ptext=paste("P = ", pvalue)
ptext
ggplot(DATAIN, aes(factor(CLUSTERCATEGORY), MEMBERCOUNT, fill = MEMBERRATING)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle("Distribution of Users by Group and Rating") +
annotate("text", label = ptext, x = 4, y = 100, fontface = 3)
product_grades<- read.csv(file="/Users/briansaindon/desktop/files/nycdsa/weeSpring/product_grades.csv", header=TRUE)
View(product_grades)
ps <- filter(product_grades,
+ product_id==341)
> table(ps$group,ps$grade
table(ps$group,ps$grade
table(ps$group,ps$grade)
table(ps$group,ps$grade)
cont.table<-table(ps$group,ps$grade)
chisq.test(cont.table)
chisq.test(ps$group,ps$grade)
chisq.test(cont.table)
chi.results<-chisq.test(cont.table)
pvalue<-chi.results$p.value
cont.table
cont.table2<as.data.frame(cont.table)
cont.table2<-as.data.frame(cont.table)
View(cont.table2)
ggplot(cont.table2, aes(factor(Var1), Freq, fill = Var2)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle("Distribution of Users by Group and Rating") +
annotate("text", label = ptext, x = 4, y = 100, fontface = 3)
cont.table2<-as.data.frame(cont.table)
ptext=paste("P = ", pvalue)
ggplot(cont.table2, aes(factor(Var1), Freq, fill = Var2)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle("Distribution of Users by Group and Rating") +
annotate("text", label = ptext, x = 4, y = 100, fontface = 3)
ggplot(cont.table2, aes(factor(Var1), Freq, fill = Var2)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle(expression(atop("Distribution of Users by Group and Rating", atop(italic(ptext), ""))))
annotate("text", label = ptext, x = 4, y = 100, fontface = 3)
ggplot(cont.table2, aes(factor(Var1), Freq, fill = Var2)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle(expression(atop("Distribution of Users by Group and Rating", atop(italic(ptext), ""))))
ggplot(cont.table2, aes(factor(Var1), Freq, fill = Var2)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle(expression(atop("Distribution of Users by Group and Rating", atop(ptext))))
annotate("text", label = ptext, x = 4, y = 100, fontface = 3)
ggplot(cont.table2, aes(factor(Var1), Freq, fill = Var2)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle(expression(atop("Distribution of Users by Group and Rating", ptext)))
annotate("text", label = ptext, x = 4, y = 100, fontface = 3)
ggplot(cont.table2, aes(factor(Var1), Freq, fill = Var2)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle("Distribution of Users by Group and Rating")
title<-paste("Distribution of Users by Group and Rating", ptext)
title
ggplot(cont.table2, aes(factor(Var1), Freq, fill = Var2)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle(title)
title<-paste("Distribution of Users by Group and Rating\n", ptext)
ggplot(cont.table2, aes(factor(Var1), Freq, fill = Var2)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle(title)
ptext=paste("P = ", round(pvalue, digits=2) )
title<-paste("Distribution of Users by Group and Rating\n", ptext)
title
ptext=paste("P = ", round(pvalue, digits=4) )
title<-paste("Distribution of Users by Group and Rating\n", ptext)
title
ggplot(cont.table2, aes(factor(Var1), Freq, fill = Var2)) +
geom_bar(stat="identity", position = "dodge") +
scale_fill_brewer(palette = "Set1") +
ggtitle(title)
annotate("text", label = ptext, x = 4, y = 100, fontface = 3)
runApp("/Users/briansaindon/desktop/files/nycdsa/weeSpring/shiny_app")
runApp("/Users/briansaindon/desktop/files/nycdsa/weeSpring/shiny_app")
runApp("/Users/briansaindon/desktop/files/nycdsa/weeSpring/shiny_app")
library(shiny)
getwd()
runApp("/Users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/Users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/Users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/Users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
getwd()
runApp("/desktop/files/nycdsa/weespring/shiny_app")
library(shiny)
getwd()
runApp("/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
contingency.table <- table(prod.scores.df$group,prod.scores.df$grade)
num.of.reviews <- nrow(prod.scores.df)
contingency.table
contingency.table==0
contingency.table<=0
chisq.test(contingency.table)$p.value
fisher.test(contingency.table)$p.value
fisher.test(prod.scores.df$group,prod.scores.df$grade)$p.value
contingency.table
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
contingency.table <- table(prod.scores.df$group,prod.scores.df$grade)
contingency.table
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
prod.scores.df <- prod.scores.df %>% filter(product_name == "Motherload Bags")
num.of.reviews <- nrow(prod.scores.df)
contingency.table <- table(prod.scores.df$group,prod.scores.df$grade)
pvalue <- chisq.test(contingency.table)$p.value
fisher.test(contingency.table)$p.value
contingency.table<=5
sum(contingency.table<=5)
sum(contingency.table<=5)>0
if sum(contingency.table<=5)>0 {
pvalue <- fisher.test(contingency.table)$p.value
}
if sum(contingency.table<=5)==0 {
pvalue <- chisq.test(contingency.table)$p.value
}
if (sum(contingency.table<=5)>0) {
pvalue <- fisher.test(contingency.table)$p.value
}
if (sum(contingency.table<=5)==0) {
pvalue <- chisq.test(contingency.table)$p.value
}
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
prod.scores.df <- prod.scores.df %>% filter(product_name == "Baby Ktan Baby Carrier")
contingency.table <- table(prod.scores.df$group,prod.scores.df$grade)
contingency.table
pvalue <- fisher.test(contingency.table)$p.value
pvalue <- fisher.test(contingency.table, hybrid = TRUE)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE, B=1e7)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE, B=1e1)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE, B=1e2)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE, B=1e1)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE, B=1e2)
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE, B=1e2)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE, B=1e2)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE, B=1e2)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE, B=1e2)$p.value
pvalue <- fisher.test(contingency.table, simulate.p.value=TRUE, B=1e2)$p.value
runApp("/users/briansaindon/desktop/files/nycdsa/weespring/shiny_app")
read.table("Users/briansaindon/downloads/MedianZIP-3 (2)", header=TRUE)
read.table("Users/briansaindon/downloads/MedianZIP-3 (2).xlsx", header=TRUE)
read.table("/Users/briansaindon/downloads/MedianZIP-3 (2).xlsx", header=TRUE)
test<-read.table("/Users/briansaindon/downloads/MedianZIP-3 (2).xlsx", header=TRUE)
urlfile <-'http://www.psc.isr.umich.edu/dis/census/Features/tract2zip/MedianZIP-3.xlsx'
destfile <- "census20062010.xlsx"
download.file(urlfile, destfile, mode="wb")
census <- read.xlsx2(destfile, sheetName = "Median")
install.packages("RCurl")
library(RCurl)
library(RCurl)
install.packages("xlsx")
library(xlsx)
urlfile <-'http://www.psc.isr.umich.edu/dis/census/Features/tract2zip/MedianZIP-3.xlsx'
destfile <- "census20062010.xlsx"
download.file(urlfile, destfile, mode="wb")
census <- read.xlsx2(destfile, sheetName = "Median")
?require()
View(census)
census <- census[c('Zip','Median..')]
names(census) <- c('Zip','Median')
census$Median <- as.character(census$Median)
census$Median <- as.numeric(gsub(',','',census$Median))
print(head(census,5))
require(zipcode)
data(zipcode)
census$Zip <- clean.zipcodes(census$Zip)
census <- merge(census, zipcode, by.x='Zip', by.y='zip')
require(ggmap)
View(census)
map<-get_map(location='united states', zoom=4, maptype = "terrain",
source='google',color='color')
map
require("ggplot2")
ggmap(map) + geom_point(
aes(x=longitude, y=latitude, show_guide = TRUE, colour=Median),
data=census, alpha=.8, na.rm = T)  +
scale_color_gradient(low="beige", high="blue")
?write.csv()
getwd()
write.csv(census, file="/Users/briansaindon/desktop/files/NYCDSA/datasci4good/alz/data/medianincomebyzip.csv")
write.table(census, file="/Users/briansaindon/desktop/files/NYCDSA/datasci4good/alz/data/medianincomebyzip.txt", sep="\t")
census <- read.xlsx2(destfile, sheetName = "Median")
# clean up data
census <- census[c('Zip','Median..', 'Pop')]
names(census) <- c('Zip','Median', 'Pop')
census$Median <- as.character(census$Median)
census$Median <- as.numeric(gsub(',','',census$Median))
print(head(census,5))
data(zipcode)
census$Zip <- clean.zipcodes(census$Zip)
census <- merge(census, zipcode, by.x='Zip', by.y='zip')
# get a Google map
View(census)
write.csv(census, file="/Users/briansaindon/desktop/files/NYCDSA/datasci4good/alz/data/medianincomebyzip.csv")
write.table(census, file="/Users/briansaindon/desktop/files/NYCDSA/datasci4good/alz/data/medianincomebyzip.txt", sep="\t")
hcc_2010<- readRDS(("../derived variables/hcc_2010.rds"))
age<- readRDS("../derived variables/age.rds")
hcc_2009<- readRDS("../derived variables/hcc_2009.rds")
summary(hcc_2010)
#HCC 19 is moderately high at 33% - model
summary_2009<- readRDS("../derived variables/summary_2009.rds")
hcc19 <- hcc_2010[c("DESYNPUF_ID", "hcc2014.19_2010")]
model.data.hcc19<- merge.data.frame(x = summary_2009, y = hcc19, by = "DESYNPUF_ID", all.x =TRUE)
model.data.hcc19<- merge.data.frame(x = model.data.hcc19, y = age, by = "DESYNPUF_ID", all.x=TRUE)
model.data.hcc19[is.na(model.data.hcc19)] <- 0
model.data.hcc19$DESYNPUF_ID <- NULL
model.data.hcc19$BENE_BIRTH_DT_2009 <- NULL
model.data.hcc19$BENE_DEATH_DT_2009 <- NULL
model.data.hcc19$BENE_SMI_CVRAGE_TOT_MONS_2009<- NULL
model.data.hcc19$PLAN_CVRG_MOS_NUM_2009<-NULL
model.data.hcc19$BENE_HI_CVRAGE_TOT_MONS_2009<-NULL
model.data.hcc19$BENE_HMO_CVRAGE_TOT_MONS_2009<-NULL
model.data.hcc19$BENE_COUNTY_CD_2009<-NULL
getwd()
hcc_2010<- readRDS(("/Desktop/cms_puf/derived variables/hcc_2010.rds"))
hcc_2010<- readRDS(("Desktop/cms_puf/derived variables/hcc_2010.rds"))
age<- readRDS("Desktop/cms_puf/derived variables/age.rds")
hcc_2009<- readRDS("Desktop/cms_puf/derived variables/hcc_2009.rds")
summary(hcc_2010)
#HCC 19 is moderately high at 33% - model
summary_2009<- readRDS("Desktop/cms_puf/derived variables/summary_2009.rds")
hcc19 <- hcc_2010[c("DESYNPUF_ID", "hcc2014.19_2010")]
model.data.hcc19<- merge.data.frame(x = summary_2009, y = hcc19, by = "DESYNPUF_ID", all.x =TRUE)
model.data.hcc19<- merge.data.frame(x = model.data.hcc19, y = age, by = "DESYNPUF_ID", all.x=TRUE)
model.data.hcc19[is.na(model.data.hcc19)] <- 0
model.data.hcc19$DESYNPUF_ID <- NULL
model.data.hcc19$BENE_BIRTH_DT_2009 <- NULL
model.data.hcc19$BENE_DEATH_DT_2009 <- NULL
model.data.hcc19$BENE_SMI_CVRAGE_TOT_MONS_2009<- NULL
model.data.hcc19$PLAN_CVRG_MOS_NUM_2009<-NULL
model.data.hcc19$BENE_HI_CVRAGE_TOT_MONS_2009<-NULL
model.data.hcc19$BENE_HMO_CVRAGE_TOT_MONS_2009<-NULL
model.data.hcc19$BENE_COUNTY_CD_2009<-NULL
set.seed(3456)
trainIndex <- createDataPartition(model.data.hcc19$hcc2014.19_2010, p = .80,
list = FALSE,
times = 1)
require(caret)
set.seed(3456)
trainIndex <- createDataPartition(model.data.hcc19$hcc2014.19_2010, p = .80,
list = FALSE,
times = 1)
head(trainIndex)
model1train <- model.data.hcc19[ trainIndex,]
model1test  <- model.data.hcc19[-trainIndex,]
table(model.data.hcc19$hcc2014.19_2010)
logit.overall = glm(hcc2014.19_2010 ~ . ,
family = "binomial",
data = model1test)
summary(logit.overall)
logit.overall1 <- step(logit.overall)
summary(logit.overall1)
scatter.smooth(logit.overall1$fit,
residuals(logit.overall, type = "deviance"),
lpars = list(col = "red"),
xlab = "Fitted Probabilities",
ylab = "Deviance Residual Values",
main = "Residual Plot for\nLogistic Regression of HCC-19 Model")
abline(h = 0, lty = 2)
library(ROCR)
# Compute AUC for predicting Class with the model
prob <- predict(logit.overall1, newdata=model1test, type="response")
pred <- prediction(prob, model1test$hcc2014.19_2010)
perftrain <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perftrain)
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc
prob <- predict(logit.overall1, newdata=model1train, type="response")
pred <- prediction(prob, model1train$hcc2014.19_2010)
perftest <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perftest)
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc
test<-as.data.frame(prob)
test$dv<-model1train$hcc2014.19_2010
View(test)
temp <- test %>% mutate(decile = ntile(prob, 10))
require(dplyr)
auc
test<-as.data.frame(prob)
test$dv<-model1train$hcc2014.19_2010
temp <- test %>% mutate(decile = ntile(prob, 10))
View(temp)
grp <- group_by(temp, decile)
average_pobability<-summarise(grp, mean=mean(prob))
View(grp)
prob <- predict(logit.overall1, newdata=model.data.hcc19, type="response")
pred <- prediction(prob, model.data.hcc19$hcc2014.19_2010)
perftest <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perftest)
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc
prob <- predict(logit.overall1, newdata=model1train, type="response")
pred <- prediction(prob, model1train$hcc2014.19_2010)
perftest <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perftest)
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc
prob <- predict(logit.overall1, newdata=model.data.hcc19, type="response")
pred <- prediction(prob, model.data.hcc19$hcc2014.19_2010)
perftest <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perftest)
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc
test<-as.data.frame(prob)
test$dv<-model1train$hcc2014.19_2010
test<-as.data.frame(prob)
test$dv<-model.data.hcc19$hcc2014.19_2010
test$desynpuf_id<-hcc_2010$DESYNPUF_ID
test$desynpuf_id<-summary_2009$DESYNPUF_ID
temp <- test %>% mutate(decile = ntile(prob, 10))
View(temp)
grp <- group_by(temp, decile)
View(grp)
average_pobability<-summarise(grp, mean=mean(prob))
View(average_pobability)
?summarise()
average_pobability<-summarise(grp, mean=mean(prob), mean2=mean(dv))
average_pobability<-summarise(grp, meanrisk=mean(prob), meanactual=mean(dv))
write.csv(temp, file="Desktop/cms_puf/scoredfile/hcc_19_scores.csv")
write.csv(temp, file="Desktop/cms_puf/scored/hcc_19_scores.csv")
View(average_pobability)
temp$riskcategory <- ifelse(temp$decile<=2,"HIGH","LOW");
View(temp)
temp$riskcategory <- ifelse(temp$decile<=2,"HIGH",
ifelse(temp$decile<=7,"MEDIUM","LOW");
temp$riskcategory <- ifelse(temp$decile<=2,"HIGH",
ifelse(temp$decile<=7,"MEDIUM","LOW"))
write.csv(temp, file="Desktop/cms_puf/scored/hcc_19_scores.csv")
View(average_pobability)
exp.test <- read.csv("/Users/briansaindon/downloads/test.csv",sep=",", header=TRUE, stringsAsFactors = FALSE, na.strings = c(" ", ""))
library(jsonlite)
metadata <- fromJSON("https://data.nasa.gov/data.json")
names(metadata$dataset)
library(dplyr)
nasa_title <- data_frame(id = metadata$dataset$`_id`$`$oid`,
title = metadata$dataset$title)
nasa_title
nasa_desc <- data_frame(id = metadata$dataset$`_id`$`$oid`,
desc = metadata$dataset$description)
nasa_desc %>%
select(desc) %>%
sample_n(5)
library(tidyr)
nasa_keyword <- data_frame(id = metadata$dataset$`_id`$`$oid`,
keyword = metadata$dataset$keyword) %>%
unnest(keyword)
nasa_keyword
library(tidytext)
nasa_title <- nasa_title %>%
unnest_tokens(word, title) %>%
anti_join(stop_words)
nasa_desc <- nasa_desc %>%
unnest_tokens(word, desc) %>%
anti_join(stop_words)
install.packages("tidytext")
install.packages("tidytext")
class(iris)
sqlQuery('select * from iris')
library(RODBC)
install.packages(("RODBC"))
sqlQuery('select * from iris')
df< - sqlQuery('select * from iris')
install.packages(("RODBC"))
library(RODBC)
model.data.hcc19<- readRDS("model.data.rds")
colnames(model.data.hcc19)
model.data.hcc19<- model.data.hcc19[c(2:17, 43, 44:122)]
model.data.hcc19$readmitted_dv<- as.factor(model.data.hcc19$readmitted_dv)
library(caret)
set.seed(3456)
trainIndex <- createDataPartition(model.data.hcc19$readmitted_dv, p = .80,
list = FALSE,
times = 1)
head(trainIndex)
model1train <- model.data.hcc19[ trainIndex,]
model1test  <- model.data.hcc19[-trainIndex,]
##############################
#####Classification Trees#####
##############################
#Loading the tree library for fitting classification and regression trees.
library(tree)
#Loading the ISLR library in order to use the Carseats dataset.
library(ISLR)
#Making data manipulation easier.
#help(Carseats)
#attach(Carseats)
#Looking at the variable of interest, Sales.
#hist(Sales)
#summary(Sales)
#Creating a binary categorical variable High based on the continuous Sales
#variable and adding it to the original data frame.
#High = ifelse(Sales <= 8, "No", "Yes")
#Carseats = data.frame(Carseats, High)
#Fit a tree to the data; note that we are excluding Sales from the formula.
#variables taken from logistic regression model stepwise
attach(model1test)
tree.carseats = tree(readmitted_dv ~ . , data = model1test)
summary(tree.carseats)
setwd("/Users/briansaindon/Desktop/ableto/derived_variables/")
model.data.hcc19<- readRDS("model.data.rds")
colnames(model.data.hcc19)
model.data.hcc19<- model.data.hcc19[c(2:17, 43, 44:122)]
model.data.hcc19$readmitted_dv<- as.factor(model.data.hcc19$readmitted_dv)
library(caret)
set.seed(3456)
trainIndex <- createDataPartition(model.data.hcc19$readmitted_dv, p = .80,
list = FALSE,
times = 1)
head(trainIndex)
model1train <- model.data.hcc19[ trainIndex,]
model1test  <- model.data.hcc19[-trainIndex,]
##############################
#####Classification Trees#####
##############################
#Loading the tree library for fitting classification and regression trees.
library(tree)
#Loading the ISLR library in order to use the Carseats dataset.
library(ISLR)
tree.carseats = tree(readmitted_dv ~ . , data = model1test)
tree.carseats = tree(readmitted_dv ~ race + gender , data = model1test)
tree.carseats = tree(readmitted_dv ~  gender , data = model1test)
summary(tree.carseats)
install.packages("xgboost")
